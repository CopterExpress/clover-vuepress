import{_ as i,r as n,o as s,c,a as e,b as r,F as d,d as o,e as a}from"./app.4f6a4bec.js";import{_ as l,a as h,b as _,c as u,d as m}from"./big_map.dc282b1a.js";const p={},g=e("h1",{id:"innopolis-open-2020-l22-\xE6ro-team",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#innopolis-open-2020-l22-\xE6ro-team","aria-hidden":"true"},"#"),o(" Innopolis Open 2020 - L22_\xC6RO team")],-1),f=e("h2",{id:"team",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#team","aria-hidden":"true"},"#"),o(" Team")],-1),b={href:"https://vk.com/vasily_0x59",target:"_blank",rel:"noopener noreferrer"},v=o("Yuryev Vasily"),k=o("."),y={href:"https://vk.com/okoneshdmitriy",target:"_blank",rel:"noopener noreferrer"},w=o("Okoneshnikov Dmitriy"),x=o("."),z=a('<h2 id="final-task-description" tabindex="-1"><a class="header-anchor" href="#final-task-description" aria-hidden="true">#</a> Final task description</h2><p>New technologies are being implemented into various sectors of the economy including agricultural industry. Drones or UAV are no exception. Thanks to their usage, assessment of agricultural territories&#39; states and analysis of landscape components became more effective and accessible.</p><img src="'+h+'" width="300" title="One of the field options"><p>The final task of Innopolis Open 2020 was dedicated to monitoring agricultural territories and consisted of the following elements:</p><ul><li>Takeoff (from QR-code) and landing (onto a small colored marker).</li><li>QR-code recognition.</li><li>Colored objects recognition (Colored markers were used to show &quot;agricultural territories&quot;).</li><li>Determination of their coordinates (their locations change).</li><li>Making a report using the gathered data.</li></ul><h2 id="code" tabindex="-1"><a class="header-anchor" href="#code" aria-hidden="true">#</a> Code</h2>',6),R=o("The code is available on GitHub: "),A={href:"https://github.com/vas0x59/ior2020_uav_L22_AERO",target:"_blank",rel:"noopener noreferrer"},T=o("https://github.com/vas0x59/ior2020_uav_L22_AERO"),C=o("."),D=a('<h2 id="main-program" tabindex="-1"><a class="header-anchor" href="#main-program" aria-hidden="true">#</a> Main program</h2><p>When implementing the code, in the original concept we used our own message types, multiple nodes, and other ROS stuff. For this you need to create a package and compile it, but due to the specifics of the competition (a single SD card was used for all teams), all the code was merged into a single file. This approach made debugging much more difficult, but running the code on the drone became much easier.</p><p>Parts of the program:</p><ol><li>Takeoff.</li><li>QR-code recognition.</li><li>Color markers recognition.</li><li>Landing.</li><li>Generating a report and a video.</li></ol><p>The final coordinates of markers are automatically grouped and averaged data from the recognition system received for the entire flight. The &quot;Zig-zag&quot; trajectory was chosen to cover the entire territory. The Gazebo simulator is used for debugging.</p><h2 id="color-markers" tabindex="-1"><a class="header-anchor" href="#color-markers" aria-hidden="true">#</a> Color markers</h2><p><code>l22_aero_vision/src/color_r_c.py</code></p><p>For image processing and object detection, we used functions from the OpenCV library.</p><p>Algorithm:</p>',9),O=e("li",null,"Receiving the image and camera parameters.",-1),j=e("li",null,"Building a mask based on a specific color range (in HSV format).",-1),V=e("li",null,"Detection of contours of colored objects.",-1),L=e("li",null,"Determining the object type, getting the key points of the object in the image.",-1),E=o("Determining the position of squares and circles using solvePnP based on the actual size of objects and key points in the image ("),M={href:"https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#ga549c2075fac14829ff4a58bc931c033d",target:"_blank",rel:"noopener noreferrer"},P=o("OpenCV Docs"),S=o(")."),q=e("li",null,[o("Sending results to the topics "),e("code",null,"/l22_aero_color/markers"),o(" and "),e("code",null,"/l22_aero_color/circles"),o(" (coordinates relative to "),e("code",null,"main_camera_optical"),o(" frame).")],-1),F=e("p",null,[o("During the development, our own message types and a service for changing the detector parameters during the landing were created. ("),e("code",null,"ColorMarker"),o(", "),e("code",null,"ColorMarkerArray"),o(", "),e("code",null,"SetParameters"),o(").")],-1),I=o("To convert the position of colored objects into "),Q=e("code",null,"aruco_map",-1),N=o(" frame TF library was used. ("),G={href:"http://wiki.ros.org/tf",target:"_blank",rel:"noopener noreferrer"},B=o("http://wiki.ros.org/tf"),H=o(")"),U=e("p",null,[o("Due to distortions at the edges of the image from the fisheye lens, all the recognized contours located near the edge of the image are ignored. This filter is disabled during landing. The object type is determined using the contour analysis functions ("),e("code",null,"approxPolyDP"),o(" - number of vertexes; "),e("code",null,"minAreaRect"),o(", "),e("code",null,"contourArea"),o(" - area of bounding rect / area of the contour; "),e("code",null,"minAreaRect"),o(" - aspect ratio).")],-1),W=e("img",{src:l,height:"355"},null,-1),Y=e("p",null,"Examples of marker recognition:",-1),Z=e("iframe",{width:"600",height:"360",src:"https://www.youtube.com/embed/kCW87RTA838",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),J=e("h2",{id:"visualization-in-rviz",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#visualization-in-rviz","aria-hidden":"true"},"#"),o(" Visualization in RViz")],-1),X=e("p",null,[e("code",null,"l22_aero_vision/src/viz.py")],-1),K=e("p",null,"To debug object recognition, a script has been created that visualizes the coordinates of markers in the RViz utility.",-1),$=e("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/6xJ33UD-NfE",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),ee=a('<h2 id="qr-code" tabindex="-1"><a class="header-anchor" href="#qr-code" aria-hidden="true">#</a> QR-code</h2><img src="'+_+'" width="400" title="A QR-code is being recognized during one of the attempts"><p>The PyZbar library was used to perform the QR-code recognition. In order to improve the accuracy of QR-code recognition, flights around the QR-code were performed at low altitude.</p><h2 id="landing" tabindex="-1"><a class="header-anchor" href="#landing" aria-hidden="true">#</a> Landing</h2><p>Landing is performed in 3 stages:</p><ol><li>Flight to the intended landing zone and hovering at an altitude of 1.5 m.</li><li>Descending to a height of 0.85 m with 3 adjustments to the marker coordinates relative to <code>aruco_map</code> frame.</li><li>Descending for several seconds with adjustments based on the coordinates of the landing marker in <code>body</code> coordinate system (since ArUco-markers may no longer be visible), instead of <code>navigate</code>,<code>set_position</code> is used.</li></ol>',6),oe=e("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/8nVGoWkdYcA",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),te=e("h2",{id:"gazebo",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#gazebo","aria-hidden":"true"},"#"),o(" Gazebo")],-1),re=e("p",null,"Due to limitations of opportunities to test the code on a real drone, we decided to use the Gazebo simulator.",-1),ae=o("To run the Clover software package in the simulator, you can use "),ie={href:"https://github.com/vas0x59/clever_sim",target:"_blank",rel:"noopener noreferrer"},ne=o("this set of scripts"),se=o(" or "),ce={href:"https://dev.px4.io/v1.9.0/en/simulation/ros_interface.html",target:"_blank",rel:"noopener noreferrer"},de=o("original instruction from PX4"),le=o("."),he=o("For Innopolis Open we have prepared several test scenes. "),_e={href:"https://github.com/vas0x59/ior2020_uav_L22_AERO_sim",target:"_blank",rel:"noopener noreferrer"},ue=o("ior2020_uav_L22_AERO_sim"),me=o("."),pe=a('<p>Also, the use of the simulator accelerated the debugging of the full code execution, since the launch was performed with real time factor = 2.5.</p><img src="'+u+'" height="250"><img src="'+m+`" height="250"><p>During testing, some problems were found (e.g. incorrect position of <code>aruco_map</code>) while using distortion in the camera plugin, so the simulator used a Pinhole camera (without any distortions from the lens).</p><h2 id="ros" tabindex="-1"><a class="header-anchor" href="#ros" aria-hidden="true">#</a> ROS</h2><p>Created nodes, topics, messages and services.</p><h3 id="nodes" tabindex="-1"><a class="header-anchor" href="#nodes" aria-hidden="true">#</a> Nodes</h3><ul><li><code>l22_aero_vision/color_r_c.py</code> - recognition of colored objects.</li><li><code>l22_aero_vision/viz.py</code> - visualization in RViz</li><li><code>l22_aero_code/full_task.py</code> - main code.</li></ul><h3 id="topics" tabindex="-1"><a class="header-anchor" href="#topics" aria-hidden="true">#</a> Topics</h3><ul><li><code>/l22_aero_color/markers</code> (<code>l22_aero_vision/ColorMarkerArray</code>) - list of rectangular markers.</li><li><code>/l22_aero_color/circles</code> (<code>l22_aero_vision/ColorMarkerArray</code>) - list of round markers.</li><li><code>/l22_aero_color/debug_img</code> (<code>sensor_msgs/Image</code>) - image for debugging.</li><li><code>/qr_debug</code> (<code>sensor_msgs/Image</code>) - image for debugging.</li></ul><h3 id="messages" tabindex="-1"><a class="header-anchor" href="#messages" aria-hidden="true">#</a> Messages</h3><h4 id="colormarker" tabindex="-1"><a class="header-anchor" href="#colormarker" aria-hidden="true">#</a> <code>ColorMarker</code></h4><div class="language-text ext-text"><pre class="language-text"><code>string color
int16 cx_img
int16 cy_img
float32 cx_cam
float32 cy_cam
float32 cz_cam
float32 size1
float32 size2
int16 type
</code></pre></div><h4 id="colormarkerarray" tabindex="-1"><a class="header-anchor" href="#colormarkerarray" aria-hidden="true">#</a> <code>ColorMarkerArray</code></h4><div class="language-text ext-text"><pre class="language-text"><code>std_msgs/Header header
l22_aero_vision/ColorMarker[] markers
</code></pre></div><h3 id="services" tabindex="-1"><a class="header-anchor" href="#services" aria-hidden="true">#</a> Services</h3><h4 id="setparameters" tabindex="-1"><a class="header-anchor" href="#setparameters" aria-hidden="true">#</a> <code>SetParameters</code></h4><div class="language-text ext-text"><pre class="language-text"><code>float32 rect_s1
float32 rect_s2
float32 circle_r
int32 obj_s_th
int32 offset_w
int32 offset_h
---
</code></pre></div>`,18);function ge(fe,be){const t=n("ExternalLinkIcon");return s(),c(d,null,[g,f,e("ul",null,[e("li",null,[e("a",b,[v,r(t)]),k]),e("li",null,[e("a",y,[w,r(t)]),x])]),z,e("p",null,[R,e("a",A,[T,r(t)]),C]),D,e("ol",null,[O,j,V,L,e("li",null,[E,e("a",M,[P,r(t)]),S]),q]),F,e("p",null,[I,Q,N,e("a",G,[B,r(t)]),H]),U,W,Y,Z,J,X,K,$,ee,oe,te,re,e("p",null,[ae,e("a",ie,[ne,r(t)]),se,e("a",ce,[de,r(t)]),le]),e("p",null,[he,e("a",_e,[ue,r(t)]),me]),pe],64)}var ye=i(p,[["render",ge],["__file","innopolis_open_L22_AERO.html.vue"]]);export{ye as default};
