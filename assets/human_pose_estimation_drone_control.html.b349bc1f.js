import{_ as i,r,o as l,c as h,a as e,b as o,w as d,F as c,e as a,d as t}from"./app.4f6a4bec.js";var u="/clover-vuepress/assets/human_pose_estimation_project_architecture.5c7a2a86.png",p="/clover-vuepress/assets/human_pose_estimation_project_poses.e73bd72b.jpg";const m={},_=a('<h1 id="human-pose-estimation-drone-control" tabindex="-1"><a class="header-anchor" href="#human-pose-estimation-drone-control" aria-hidden="true">#</a> Human Pose Estimation drone control</h1><h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true">#</a> Introduction</h2><p>Human pose estimation is one of the computer vision applications in order to estimate all the joints and the different poses of the human body through a special camera and a special hardware or process the images from a regular camera by machine learning and deep learning techniques. This project is about controlling the drone through the poses of a person in front of regular camera without needing to an external hardware or hard build dependencies on your computer.</p><h2 id="demo" tabindex="-1"><a class="header-anchor" href="#demo" aria-hidden="true">#</a> Demo</h2>',4),f=e("iframe",{width:"770",height:"421",src:"https://www.youtube.com/embed/ucPONeHg2lk",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),g=e("iframe",{width:"853",height:"480",src:"https://www.youtube.com/embed/EDcTtPLxzoU",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),b=e("p",null,"In the demo video, we were using Ubuntu 18.04 and clever4 drone.",-1),w=e("h2",{id:"development",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#development","aria-hidden":"true"},"#"),t(" Development")],-1),y=t("We used posenet from tensorflow.js as our human pose estimation module because it is easier to use, build, fast and compatible with different environments(Hardware and OS). You can find the work of posenet for this project "),v={href:"https://github.com/hany606/tfjs-posenet",target:"_blank",rel:"noopener noreferrer"},k=t("here"),x=t(". Websockets were used as communication protocol between the browser and a running server on the drone."),j=e("h2",{id:"architecture",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#architecture","aria-hidden":"true"},"#"),t(" Architecture")],-1),I=e("p",null,"The image below is a visualization of our architecture for the project.",-1),C=e("p",null,[e("img",{src:u,alt:"Architecture"})],-1),P=t("This figure is made from "),E={href:"https://www.draw.io/",target:"_blank",rel:"noopener noreferrer"},R=t("here"),O=e("h2",{id:"dependencies",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#dependencies","aria-hidden":"true"},"#"),t(" Dependencies")],-1),T=e("p",null,"Before you test it you need to install on your laptop:",-1),H=t("Install Nodejs from "),A={href:"https://nodejs.org/en/download/",target:"_blank",rel:"noopener noreferrer"},D=t("here"),N=t(". For "),S={href:"https://tecadmin.net/install-latest-nodejs-npm-on-ubuntu/",target:"_blank",rel:"noopener noreferrer"},W=t("Ubuntu installation"),q=t("Install Yarn package manager from "),X={href:"https://yarnpkg.com/lang/en/docs/install/",target:"_blank",rel:"noopener noreferrer"},F=t("here"),U=t(". "),L={href:"https://github.com/yarnpkg/yarn/issues/3189",target:"_blank",rel:"noopener noreferrer"},B=t("Usual problem"),V=t(" while installing and using yarn with Ubuntu."),Y=e("li",null,"Have an experience in manual control on the drone in case of any weird behavior happen.",-1),G=t("Worked before with COEX drones, if this is your first time to work with COEX drones check "),M={href:"https://clover.coex.tech/en/",target:"_blank",rel:"noopener noreferrer"},z=t("this"),J=t("."),K=a(`<p>and you are ready to build and use the required codes.</p><h2 id="setup-installation" tabindex="-1"><a class="header-anchor" href="#setup-installation" aria-hidden="true">#</a> Setup &amp; installation</h2><h3 id="in-your-main-laptop" tabindex="-1"><a class="header-anchor" href="#in-your-main-laptop" aria-hidden="true">#</a> In your main laptop</h3><h4 id="it-has-been-tested-until-now-only-on-ubuntu-18-04" tabindex="-1"><a class="header-anchor" href="#it-has-been-tested-until-now-only-on-ubuntu-18-04" aria-hidden="true">#</a> (It has been tested until now only on Ubuntu 18.04)</h4><ul><li>Clone the repo of posenet in your computer or download it if you are using Windows without GitHub</li></ul><div class="language-bash ext-sh"><pre class="language-bash"><code><span class="token function">git</span> clone https://github.com/hany606/tfjs-posenet.git
</code></pre></div>`,6),Q=t("Do the steps of running and setup as it is described in the README "),Z={href:"https://github.com/hany606/tfjs-posenet/tree/master/posenet",target:"_blank",rel:"noopener noreferrer"},$=t("here"),ee=e("h3",{id:"in-the-raspberry-pi-of-the-drone-main-controller",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#in-the-raspberry-pi-of-the-drone-main-controller","aria-hidden":"true"},"#"),t(" In the Raspberry Pi of the drone (Main controller)")],-1),te=e("li",null,"Access the Raspberry Pi",-1),oe=t("Switch to Client mode"),ne=t(" and ensure that the network has internet connection."),ae=a(`<p>Notice: I have already made a bash script based on that tutorial, it is in COEX-Internship19/helpers/ called .to_client.bash To run it:</p><div class="language-bash ext-sh"><pre class="language-bash"><code><span class="token function">chmod</span> +x .to_client.bash
./.to_client <span class="token operator">&lt;</span>NAME_OF_NETWORK<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>PASSWORD<span class="token operator">&gt;</span>
</code></pre></div><ul><li>Install the tornado library to make a WebSocket server</li></ul><div class="language-bash ext-sh"><pre class="language-bash"><code><span class="token function">sudo</span> pip <span class="token function">install</span> tornado
</code></pre></div><ul><li>Clone the main repo on the Raspberry Pi of the drone</li></ul><div class="language-bash ext-sh"><pre class="language-bash"><code><span class="token function">git</span> clone https://github.com/hany606/COEX-Internship19.git
</code></pre></div><ul><li>Go to the project directory</li></ul><div class="language-bash ext-sh"><pre class="language-bash"><code><span class="token builtin class-name">cd</span> COEX-Internship19/projects/Human_pose_estimation_drone_control/
</code></pre></div><ul><li>Run the server to test that everything is correct and run the posenet, you should see a lot of data is printed in the terminal (if you are running the human pose estimation code on your main computer, just refresh the page in the browser after running the below command in Raspberry Pi)</li></ul><div class="language-bash ext-sh"><pre class="language-bash"><code>python websocket_server_test.py
</code></pre></div><ul><li>Close the server using Ctrl+C</li><li>To run the main file</li></ul><div class="language-bash ext-sh"><pre class="language-bash"><code>python main_drone.py
</code></pre></div><h2 id="how-to-use-it" tabindex="-1"><a class="header-anchor" href="#how-to-use-it" aria-hidden="true">#</a> How to use it</h2><ul><li>Run the server first from the Raspberry Pi from the correct directory</li></ul><div class="language-bash ext-sh"><pre class="language-bash"><code>python main_drone.py
</code></pre></div><ul><li>Run Human pose estimation module on your laptop with WebSocket by</li></ul><div class="language-bash ext-sh"><pre class="language-bash"><code><span class="token function">yarn</span> websocket
</code></pre></div><p>Or refresh the page if you already run it.</p><ul><li>You should see the instructions on the screen of the terminal of the Raspberry Pi right now.</li><li>Firstly, you should be visible for the camera and it is better to have a clear background without many details.</li><li>Secondly, you should do initial pose as it is described in the images below.</li><li>You can perform any pose and try to keep it until your drone finish doing this move that is corresponding to the pose.</li><li>After you do the pose return to the initial pose in order to give the drone the command to listen to another pose.</li><li>If you want to stop the program, land the drone and don&#39;t return to the initial pose and press Ctrl+C to stop the drone.</li></ul><h2 id="poses" tabindex="-1"><a class="header-anchor" href="#poses" aria-hidden="true">#</a> Poses</h2><p><img src="`+p+'" alt="Poses"></p>',21),re=t("Animation is created by "),se={href:"https://justsketchme.web.app/",target:"_blank",rel:"noopener noreferrer"},ie=t("this"),le=a('<h2 id="notes" tabindex="-1"><a class="header-anchor" href="#notes" aria-hidden="true">#</a> Notes</h2><ul><li>Websockets are used to communicate between the page on the browser that runs posenet and the drone.</li><li>As the model of posenet is already pre-trained and using tensorflow.js. So, it is quite fast and can run on different computers without any problems thanks to yarn, parcel and tensorflow.js, and we have configured the code of posenet to the minimal configuration to not require a lot of computation power.</li><li>This project has been built in 1 week of working, it took a lot of time trying to make openpose and google colab working but unfortunately I had many errors and one I decided to move to posenet everything was pretty easy.</li><li>If you have any comments about the codes to try to improve it, I will be happy if you can contact me through telegram: @hany606 or email: <a href="mailto:h.hamed.elanwar@gmail.com">h.hamed.elanwar@gmail.com</a> or do pull requests.</li><li>If you have implemented any of the applications below, or do some improvements, we will be very happy for that.</li></ul><h2 id="future-application" tabindex="-1"><a class="header-anchor" href="#future-application" aria-hidden="true">#</a> Future application</h2>',3),he={href:"https://web.facebook.com/COEXDrones/photos/pcb.1129309377266616/1129308437266710/?type=3&theater",target:"_blank",rel:"noopener noreferrer"},de=t("Drone wars"),ce=t(": Control the drone during the drones battle using human poses. It requires high speed interaction and more precise control."),ue=e("li",null,"Control a drone that draw graffiti using human poses and draw in real-time.",-1),pe=e("li",null,"Playing with balls like ping pong game with the drones. It may require 3D Human Pose estimation Algorithms.",-1),me=e("li",null,"Control two drones by your arms and do some task together.",-1),_e=a('<h2 id="acknowledgments" tabindex="-1"><a class="header-anchor" href="#acknowledgments" aria-hidden="true">#</a> Acknowledgments</h2><ul><li>This project was part of an internship in COEX in July 2019. if you found any bugs or problems, you can contact me through telegram: @hany606 or email: <a href="mailto:h.hamed.elanwar@gmail.com">h.hamed.elanwar@gmail.com</a>.</li><li>The above applications were thought by me and my internship supervisor Timofey.</li></ul><h2 id="references" tabindex="-1"><a class="header-anchor" href="#references" aria-hidden="true">#</a> References</h2>',3),fe={href:"https://blog.nanonets.com/human-pose-estimation-2d-guide/",target:"_blank",rel:"noopener noreferrer"},ge=t("Human pose estimation guide"),be={href:"https://clover.coex.tech/en/",target:"_blank",rel:"noopener noreferrer"},we=t("Clover drones tutorials"),ye={href:"https://github.com/tensorflow/tfjs-models/tree/master/posenet",target:"_blank",rel:"noopener noreferrer"},ve=t("Posenet GitHub repo"),ke={href:"https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5",target:"_blank",rel:"noopener noreferrer"},xe=t("Posenet meduim article"),je={href:"https://www.tensorflow.org/js/demos",target:"_blank",rel:"noopener noreferrer"},Ie=t("Tensorflow.js demos"),Ce={href:"https://www.tensorflow.org/lite/models/pose_estimation/overview",target:"_blank",rel:"noopener noreferrer"},Pe=t("Posenet overview");function Ee(Re,Oe){const n=r("ExternalLinkIcon"),s=r("RouterLink");return l(),h(c,null,[_,f,g,b,w,e("p",null,[y,e("a",v,[k,o(n)]),x]),j,I,C,e("p",null,[P,e("a",E,[R,o(n)])]),O,T,e("ul",null,[e("li",null,[H,e("a",A,[D,o(n)]),N,e("a",S,[W,o(n)])]),e("li",null,[q,e("a",X,[F,o(n)]),U,e("a",L,[B,o(n)]),V]),Y,e("li",null,[G,e("a",M,[z,o(n)]),J])]),K,e("ul",null,[e("li",null,[Q,e("a",Z,[$,o(n)])])]),ee,e("ul",null,[te,e("li",null,[o(s,{to:"/en/network.html"},{default:d(()=>[oe]),_:1}),ne])]),ae,e("p",null,[re,e("a",se,[ie,o(n)])]),le,e("ul",null,[e("li",null,[e("a",he,[de,o(n)]),ce]),ue,pe,me]),_e,e("ul",null,[e("li",null,[e("a",fe,[ge,o(n)])]),e("li",null,[e("a",be,[we,o(n)])]),e("li",null,[e("a",ye,[ve,o(n)])]),e("li",null,[e("a",ke,[xe,o(n)])]),e("li",null,[e("a",je,[Ie,o(n)])]),e("li",null,[e("a",Ce,[Pe,o(n)])])])],64)}var He=i(m,[["render",Ee],["__file","human_pose_estimation_drone_control.html.vue"]]);export{He as default};
